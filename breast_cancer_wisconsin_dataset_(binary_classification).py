# -*- coding: utf-8 -*-
"""Breast Cancer Wisconsin Dataset (Binary Classification).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iWgL-ThAeUYSXlYU9jeCBKeYG_zUpTIc
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras import regularizers # Import the regularizers module
import pandas as pd
import seaborn as sns

data = load_breast_cancer()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

# Column names (features)
print("Feature Names:", data.feature_names)

df.head()

df.info()

df.describe()

# 2. Target Distribution
plt.figure(figsize=(6,4))
sns.countplot(x='target', data=df, palette='Set2')
plt.xticks([0,1], ['Malignant (0)', 'Benign (1)'])
plt.title("Target Class Distribution")
plt.show()

plt.figure(figsize=(15,8))
corr = df.corr()
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap (first 15 features)")
plt.show()

plt.figure(figsize=(12,6))
for i, col in enumerate(['mean radius', 'mean texture', 'mean area', 'mean smoothness']):
    plt.subplot(2,2,i+1)
    sns.histplot(df, x=col, hue="target", bins=30, kde=True, palette="Set1")
    plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()

sns.pairplot(df, hue='target', diag_kind='kde', markers=True, palette='Set2')
plt.show()



X =df.drop('target',axis=1)
y = df.target

import joblib
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)


scaler = StandardScaler()
X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X.columns)
X_test = pd.DataFrame(scaler.transform(X_test),columns=X.columns)

# Save the scaler
scaler=joblib.dump(scaler, "scaler.pkl")

corrs = X_train.corrwith(y_train).sort_values(key=lambda s: s.abs(), ascending=False)

corrs.head(15)

corrs_df = corrs.reset_index()
corrs_df.columns = ['Feature', 'Correlation']

print(corrs_df.head(15))

X_train

print("Features:", X.shape[1])
print("Classes:", data.target_names)

# Define regularization strength
l2_reg = 0.01  # You can adjust this value

model = Sequential([
    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)),
    Dropout(0.2),
    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_reg)),
    Dropout(0.2),
    Dense(1, activation='sigmoid')   # Binary output (0 or 1)
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train, y_train,
                    validation_data=(X_test, y_test),
                    epochs=50, batch_size=0, verbose=1)

loss, acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\n✅ Test Accuracy: {acc:.4f}")

plt.figure(figsize=(12,5))

# Accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title("Model Accuracy")

# Loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title("Model Loss")

loss, acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\n✅ Test Accuracy: {acc:.4f}")

import joblib

# Save trained model
joblib.dump(model, "breast_cancer_model.pkl")

# Load model
model = joblib.load("breast_cancer_model.pkl")

features = ['mean radius', 'mean texture', 'mean area', 'mean smoothness']

17.99	10.38	122.80	1001.0	0.11840	0.27760	0.3001	0.14710	0.2419	0.07871	...	17.33	184.60	2019.0	0.1622	0.6656	0.7119	0.2654	0.4601	0.11890

X_train.head(1)

import numpy as np
import pandas as pd

# Example new patient data (replace with real input)
new_patient = pd.DataFrame([{
    'mean radius': 14.5,
    'mean texture': 20.3,
    'mean perimeter': 97.0,
    'mean area': 910.2,
    'mean smoothness': 0.1,
    'mean compactness': 0.15,
    'mean concavity': 0.2,
    'mean concave points': 0.1,
    'mean symmetry': 0.2,
    'mean fractal dimension': 0.06,
    'radius error': 0,  # Adding missing features with placeholder values
    'texture error': 0,
    'perimeter error': 0,
    'area error': 0,
    'smoothness error': 0,
    'compactness error': 0,
    'concavity error': 0,
    'concave points error': 0,
    'symmetry error': 0,
    'fractal dimension error': 0,
    'worst radius': 0,
    'worst texture': 0,
    'worst perimeter': 0,
    'worst area': 0,
    'worst smoothness': 0,
    'worst compactness': 0,
    'worst concavity': 0,
    'worst concave points': 0,
    'worst symmetry': 0,
    'worst fractal dimension': 0
}])

loaded_model = joblib.load("breast_cancer_model.pkl")
loaded_scaler = joblib.load("scaler.pkl")

new_patient_scaled = loaded_scaler.transform(new_patient)

probability = model.predict(new_patient_scaled)

# Convert probability → class (0 or 1)
prediction = (probability > 0.5).astype("int32")

print("Prediction:", "Malignant" if prediction[0][0]==1 else "Benign")
print("Probability (Malignant):", probability[0][0])

probabilities = model.predict(new_patient_scaled)

# Pick class with highest probability
prediction = probabilities.argmax(axis=1)

print("Predicted Class:", prediction[0])
print("Class Probabilities:", probabilities[0])



